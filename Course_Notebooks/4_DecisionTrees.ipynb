{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ML-AI4Econ Course**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first download the different packages needed for this part of the course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing, load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree, DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also set a random seed for reproducible results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most interpretable and easy-to-understand algorithms are binary decision trees. Decision trees are just what they sound like, they are (inverted) trees for which each branch in the tree has some decision rule with respect to some variable that allows to classify an observation to one or another region and, at the last \"leaf\", we make a prediction depending on the resulting region.\n",
    "\n",
    "We have both regression and classification trees, so we can use this algorithm for both tasks. However, there are different aspects that are interesting to explore when estimating these models. For this purpose, we use two different datasets on go through a complete process to estimate an optimized model for our data.\n",
    "\n",
    "Of course, we first start by downloading the data, and then we go to regression trees to finish with classification trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_california_housing(as_frame=True)\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "print(\"Dataset description:\\n\", data.DESCR)\n",
    "print(\"\\nThese are the original explanatory variables:\\n\\n\",X,\"\\n\")\n",
    "print(\"\\nThese are the prices for each observation (the target variable):\\n\\n\",y,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we divide the sample in train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will estimate a regression decision tree with the default hyperparameters and a cross-validation error estimate to check the performance of an \"automatic model\". That is, a model in which we do not tune hyperparameters nor modify different aspects of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeRegressor(random_state=42)\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Which is the estimation for the generalization error?\n",
    "\n",
    "cv_scores = cross_val_score(dtree, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mse = -np.mean(cv_scores)\n",
    "print(\"Cross-validated MSE (initial tree): {:.4f}\".format(cv_mse),\"\\n\")\n",
    "\n",
    "# Let us see the test performance\n",
    "\n",
    "y_pred = dtree.predict(X_test)\n",
    "mae_initial = mean_absolute_error(y_test, y_pred)\n",
    "mse_initial = mean_squared_error(y_test, y_pred)\n",
    "r2_initial = r2_score(y_test, y_pred)\n",
    "print(\"Initial Decision Tree Performance:\\n\")\n",
    "print(\"MSE: {:.4f}\".format(mse_initial))\n",
    "print(\"MAE: {:.4f}\".format(mae_initial))\n",
    "print(\"R^2: {:.4f}\".format(r2_initial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how does the tree look like through an special plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(dtree, feature_names=X.columns, filled=True, rounded=True, max_depth=3)\n",
    "plt.title(\"Original Decision Tree (limited to depth 6 for visualization)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to improve our model by changing the hyperparameters and elements of our tree. One of the most important ones might be the depth of the tree, which can be understood as how many decision rules or branches should our tree have. By balancing the training error and complexity through cost complexity prunning, we might obtain better generalization performance and avoid overfitting.\n",
    "\n",
    "The effective cost of a tree $T$ is defined as:\n",
    "\n",
    "$$\n",
    "\\text{Cost}(T) = \\text{Error}(T) + \\alpha \\times \\text{Complexity}(T)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\text{Error}(T)$ is the error measure (such as the sum of squared errors for regression or misclassification error for classification).\n",
    "- $\\text{Complexity}(T)$ is typically related to the number of terminal nodes (leaves) in the tree.\n",
    "- $\\alpha$ is a tuning parameter that controls the trade-off between the modelâ€™s fit and its complexity.\n",
    "\n",
    "A higher value of $\\alpha$ penalizes complex trees more, leading to a simpler tree by removing splits (branches) that do not contribute significantly to reducing the error.\n",
    "\n",
    "In summary, pruning removes branches that capture noise rather than useful patterns, resulting in a more robust model that is less likely to overfit the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dtree.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "print(\"\\nNumber of candidate alphas for pruning: \", len(ccp_alphas))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(ccp_alphas, impurities, marker='o', drawstyle=\"steps-post\")\n",
    "plt.xlabel(\"Effective alpha\")\n",
    "plt.ylabel(\"Total impurity of leaves\")\n",
    "plt.title(\"Impurity vs effective alpha for training set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'ccp_alpha': np.linspace(ccp_alphas[1], ccp_alphas[-1], num=10)}  # skip the first alpha=0\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(random_state=42),\n",
    "                           param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_alpha = grid_search.best_params_['ccp_alpha']\n",
    "print(\"\\nBest alpha from GridSearchCV: \", best_alpha)\n",
    "\n",
    "pruned_tree = grid_search.best_estimator_\n",
    "\n",
    "# Performance evaluation\n",
    "\n",
    "y_pred_pruned = pruned_tree.predict(X_test)\n",
    "mse_pruned = mean_squared_error(y_test, y_pred_pruned)\n",
    "mae_pruned = mean_absolute_error(y_test, y_pred_pruned)\n",
    "r2_pruned = r2_score(y_test, y_pred_pruned)\n",
    "print(\"\\nPruned Decision Tree Performance:\\n\")\n",
    "print(\"MSE: {:.4f}\".format(mse_pruned))\n",
    "print(\"MAE: {:.4f}\".format(mae_pruned))\n",
    "print(\"R^2: {:.4f}\".format(r2_pruned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take a look at the prunned tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(pruned_tree, feature_names=X.columns, filled=True, rounded=True, max_depth=3)\n",
    "plt.title(\"Pruned Decision Tree (limited to depth 3 for visualization)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we have improved our test performance. However, we can still optimize other hyperparameters to have better performance. Let us see what happens when we tweak other parameters, such as maximum depth or the number of samples per node/leaf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'ccp_alpha': np.linspace(ccp_alphas[1], ccp_alphas[-1], num=10),\n",
    "                  'max_depth': [None, 5, 10, 15, 20],\n",
    "                  'min_samples_split': [2, 5, 10],\n",
    "                  'min_samples_leaf': [1, 2, 4]}  # skip the first alpha=0\n",
    "grid_search = GridSearchCV(DecisionTreeRegressor(random_state=42),\n",
    "                           param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_alpha = grid_search.best_params_['ccp_alpha']\n",
    "print(\"\\nBest alpha from GridSearchCV: \", best_alpha)\n",
    "\n",
    "pruned_tree = grid_search.best_estimator_\n",
    "\n",
    "# Performance evaluation\n",
    "\n",
    "y_pred_pruned = pruned_tree.predict(X_test)\n",
    "mse_pruned = mean_squared_error(y_test, y_pred_pruned)\n",
    "mae_pruned = mean_absolute_error(y_test, y_pred_pruned)\n",
    "r2_pruned = r2_score(y_test, y_pred_pruned)\n",
    "print(\"\\nPruned Decision Tree Performance:\\n\")\n",
    "print(\"MSE: {:.4f}\".format(mse_pruned))\n",
    "print(\"MAE: {:.4f}\".format(mae_pruned))\n",
    "print(\"R^2: {:.4f}\".format(r2_pruned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now take a look at the tuned tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(pruned_tree, feature_names=X.columns, filled=True, rounded=True, max_depth=3)\n",
    "plt.title(\"Pruned Decision Tree (limited to depth 3 for visualization)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, we can even compute which variables are more important variables thorugh a concept called **feature importance**. In decision trees and ensemble methods like Random Forests, feature importance is computed based on the idea of **impurity reduction**. Here's a breakdown of the process:\n",
    "\n",
    "1. **Impurity Measures:**  \n",
    "\n",
    "   - For **classification trees**, impurity is commonly measured using the **Gini impurity** or **entropy**.  \n",
    "   - For **regression trees**, impurity is typically measured as the **variance** (often via Mean Squared Error).\n",
    "\n",
    "2. **Impurity Decrease at a Node:**  \n",
    "\n",
    "   When a node splits, the goal is to reduce the impurity. The decrease in impurity resulting from a split is calculated as:\n",
    "\n",
    "   $$\n",
    "   \\Delta I = I(\\text{parent}) - \\sum_{i=1}^{k} \\frac{N_i}{N_{\\text{parent}}} \\, I(i)\n",
    "   $$\n",
    "\n",
    "   where:  \n",
    "   - $I(\\text{parent})$ is the impurity of the parent node,  \n",
    "   - $I(i)$ is the impurity of the $i$-th child node,  \n",
    "   - $N_i$ is the number of samples in the $i$-th child,  \n",
    "   - $N_{\\text{parent}}$ is the total number of samples in the parent node, and  \n",
    "   - $k$ is the number of child nodes (usually 2 in binary trees).\n",
    "\n",
    "3. **Assigning Importance to Features:**\n",
    "\n",
    "   The improvement (or decrease) in impurity $\\Delta I$ is attributed to the feature used to split the node. This improvement is typically **weighted** by the fraction of samples reaching that node.\n",
    "\n",
    "4. **Aggregating Over the Entire Tree:**  \n",
    "\n",
    "   The importance for each feature is computed by summing the weighted impurity decreases for all nodes where that feature is used. Finally, these values are normalized so that the importances for all features add up to 1 (or 100%).\n",
    "\n",
    "In essence, a feature is considered important if it consistently leads to large reductions in impurity across many nodes in the tree. Hence, let us see which variable allows to separate observations the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pruned_tree.feature_importances_\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importances of the Best Model\")\n",
    "plt.gca().invert_yaxis()  # Highest importance at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen a simple workflow applied to regression decision trees, we can now delve into classification tasks with this algorithm. We will use a different dataset, but we will still use the same workflow than that for the regression tree. We just want to look at an example for classification, but it is merely the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "y = pd.Series(data.target, name='target')\n",
    "\n",
    "print(\"Dataset Description:\\n\\n\")\n",
    "print(data.DESCR)\n",
    "print(\"\\nFeatures:\\n\\n\")\n",
    "print(X.head())\n",
    "print(\"\\nTarget:\\n\\n\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we compute first a simple tree, as before, to compare it to a tuned model afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tree = DecisionTreeClassifier(random_state=42)\n",
    "simple_tree.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the simple model on the test set\n",
    "\n",
    "y_pred_simple = simple_tree.predict(X_test)\n",
    "accuracy_simple = accuracy_score(y_test, y_pred_simple)\n",
    "print(\"\\nSimple Decision Tree Performance:\")\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_simple))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_simple))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting tree will be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(simple_tree, feature_names=X.columns, class_names=data.target_names,\n",
    "          filled=True, rounded=True, max_depth=3)\n",
    "plt.title(\"Simple Decision Tree (Depth limited to 3)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we providde a tuned model which should improve the test performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = simple_tree.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas = path.ccp_alphas\n",
    "print(\"\\nNumber of candidate alphas for pruning: \", len(ccp_alphas))\n",
    "\n",
    "alpha_candidates = np.linspace(ccp_alphas[1], ccp_alphas[-1], num=10)\n",
    "\n",
    "param_grid = {\n",
    "    'ccp_alpha': alpha_candidates,\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42),\n",
    "                           param_grid,\n",
    "                           cv=5,\n",
    "                           scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_tree = grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nBest Parameters from GridSearchCV:\")\n",
    "print(best_params)\n",
    "\n",
    "# Performance Evaluation\n",
    "\n",
    "y_pred_tuned = best_tree.predict(X_test)\n",
    "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "print(\"\\nTuned Decision Tree Performance:\")\n",
    "print(\"Accuracy: {:.4f}\".format(accuracy_tuned))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_tuned))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_tuned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tree looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(best_tree, feature_names=X.columns, class_names=data.target_names,\n",
    "          filled=True, rounded=True, max_depth=3)\n",
    "plt.title(\"Tuned Decision Tree (Depth limited to 3)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this tuned model, we can see which are the most important variables through the feature importance plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = best_tree.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Feature Importances of the Tuned Decision Tree\")\n",
    "plt.gca().invert_yaxis()  # Highest importance at the top\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are a bunch of exercises for testing your understanding. Please do not use LLMs or ChatGPT to answer them (unless you are explicitly ordered to do so), but look at the documentation of different packages and websites for a better control of Python packages for ML \\& AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise 1: Understanding Trees**\n",
    "**Objective:** Understand the mechanics of a decision tree.\n",
    "\n",
    "- What happens when we do not restrict the depth of a tree and go for the maximum branching possible?\n",
    "- What would be the prediction of the leafs in each case?\n",
    "- Seems like the value predicted for a parent node of the regression tree is higher than the one predicted for one branch and lower for the other. Why is that?\n",
    "- Does the cost complexity prunning formula remind you of some method we used for regressions?\n",
    "- What does impurity measure, given the functions used for its computation? Why do we want to reduce it?\n",
    "\n",
    "### **Exercise 2: Hyperparameter Tuning and Model Evaluation**  \n",
    "**Objective:** Explore the impact of hyperparameters on the performance of decision trees.  \n",
    "- Train an unpruned decision tree on a another regression dataset and record its performance metrics (MSE, MAE, RÂ²) on both the training and test sets.  \n",
    "- Use GridSearchCV to tune key hyperparameters such as `ccp_alpha`, `max_depth`, `min_samples_split`, and `min_samples_leaf`. What are the best parameters found?  \n",
    "- Compare the performance of the tuned model with that of the unpruned model. What improvements do you observe, and why might these improvements occur?\n",
    "\n",
    "### **Exercise 3: Feature Importance and Model Interpretation**  \n",
    "**Objective:** Understand and interpret feature importance in tree-based models.  \n",
    "- After tuning your decision tree regressor, extract the feature importances using the `feature_importances_` attribute.  \n",
    "- Create a horizontal bar chart that visualizes the importance of each feature.  \n",
    "- Identify the top three most important features and discuss why they might be influential in predicting the target variable.  \n",
    "- Suggest ways you might use this information to further improve the model (e.g., by selecting features or engineering new ones).\n",
    "\n",
    "### **Exercise 4: Classification with Decision Trees**  \n",
    "**Objective:** Apply decision trees for classification and evaluate model performance.  \n",
    "- Using a another classification dataset, train a simple decision tree classifier.  \n",
    "- Evaluate the model using accuracy, precision, recall, F1 score, and by constructing a confusion matrix.  \n",
    "- Perform hyperparameter tuning, including cost complexity pruning, with GridSearchCV to optimize the classifier's performance.  \n",
    "- Compare the performance of the simple classifier with that of the tuned classifier. What differences do you observe?\n",
    "\n",
    "### **Exercise 5: Comparing Linear and Non-linear Classification Methods**  \n",
    "**Objective:** Compare logistic regression with LDA and QDA on a classification task.  \n",
    "- Train a logistic regression model on the Iris dataset and evaluate its performance.  \n",
    "- Train LDA and QDA models on the same dataset.  \n",
    "- Use PCA (if necessary) to reduce the feature space to 2 dimensions, and visualize the decision boundaries of each model.  \n",
    "- Discuss the differences in performance and decision boundaries. Which model seems to perform best and why might that be the case?\n",
    "\n",
    "### **Exercise 6: Overfitting, Underfitting, and the Role of Pruning**  \n",
    "**Objective:** Understand the concepts of overfitting and underfitting in decision trees and how pruning can help.  \n",
    "- On a regression dataset, train decision trees with varying values of `max_depth` and observe how the training and test errors change.  \n",
    "- Plot the training error and test error as functions of tree depth. At what point do you notice signs of overfitting?  \n",
    "- Apply cost complexity pruning to your tree, and compare the performance (using cross-validation) of the pruned tree to the unpruned tree.  \n",
    "- Explain how pruning helps achieve a better bias-variance tradeoff and why this is beneficial for generalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
